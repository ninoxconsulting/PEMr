---
title: "Run_forest_model_06.rmd"
author: "Gen Perkins"
date: "2025-12-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Run the forest model

As the forest model is the primary research focus of this mapping process this will be the most detailed and require input in decision making to maximize the accuracy for intended purpose. 

## 1) Prepare training data and required inputs for modelling

The first step is to prepare the training data for the model. This includes the following steps:
1) convert prepared points to a csv file named training_pts.csv
2) generate a full covariate list as an RDS object


Note the attribute listed in the prep_tps function should be the attribute within the mapkey to which the raw fieldcalls will be matched. For forested maps this is typically the mapunit_ss_realm, however users can specify their own column if required.

If an error occurs is it worthwhile testing if the min_no is too low and increasing this value. A minimum of 20 appear to be a good starting point.



```{r}
#| eval: false
#might want to generate a subfolder here but keeping it at root level for now

out_dir = fs::path(PEMprepr::read_fid()$dir_3020_draft$path_rel, "20_f")

allpts = sf::st_read(fs::path(PEMprepr::read_fid()$dir_20105030_attributed_field_data$path_rel, "allpoints_att.gpkg"))
mapkey = read.csv(fs::path(PEMprepr::read_fid()$dir_30_model$path_abs,"mapunitkey_final.csv"))
covarkey = read.csv(fs::path(PEMprepr::read_fid()$dir_30_model$path_rel,"covar_key.csv"))

forest_nonforest_binary = terra::rast(fs::path(PEMprepr::read_fid()$dir_3010_inputs$path_abs, "forest_nonforest_final.tif"))
bec = sf::st_read(fs::path(PEMprepr::read_fid()$dir_1010_vector$path_rel, "bec.gpkg"))


## 1.1 prep all training points

tpts <- prep_tps(
  allpts = allpts, 
  mapkey = mapkey, 
  covarkey = covarkey,
  attribute = "mapunit_ss_realm",
  bec = bec,
  min_no = 20)

# review the breakdown of records
#dplyr::count(tpts, bgc_cat, data_type)
#dplyr::count(tpts, mapunit1)



## generate a full list of covariates 

core_names  <- covarkey |>
  dplyr::filter(type == "core") |>
  dplyr::select(value) |> dplyr::pull()

mcols <- names(tpts)[!names(tpts) %in% c(core_names)]
saveRDS(mcols, fs::path(out_dir, "full_covariate_list.rds"))


# convert training points file to csv

tpts <- cbind(tpts, as.data.frame(sf::st_coordinates(tpts))) |>
  sf::st_drop_geometry()

write.csv(tpts, fs::path(out_dir, "training_pts.csv"), row.names = FALSE)

```


1.2) Generate a fuzzy matrix. 

To assist in accuracy assessment we need to generate a fuzzy metrics. This provides a list of all mapunits  we need to create a table which assigns partial correct values for mapunit calls that are similar (on the edatopic position) to the correct calls. In this case, scores could be awarded for on a sliding scale from 1 (Correct) to 0 (nowhere close) with partial credit assigned to closely related mapunits. Note this requires a matrix which specifies the similarity between all combinations of possible calls. 

The final output is a list of all mapunits within the tpts$mapunit1 column and cross reference with all other units with an equivalent value between 0 and 1. The dataframe consists of three columns: target, Pred, f. 

```{r}
#| eval: false

# check if csv already is present
if(!file.exists(fs::path(out_dir, "fuzzy_matrix.csv"))){

  print("generating fuzzy matrix")

fmat <- generate_fuzzymatrix(tpts, 
                             "bgc_cat", 
                             out_dir = out_dir,
                             out_name = "fuzzy_matrix.csv",
                             write_output = FALSE,
                             overwrite = TRUE)
}

fmat <- read.csv(fs::path(out_dir, "fuzzy_matrix.csv" ))

```

Note a warning message will show if not all units are included in the fuzzy matrix. This will need to be manually checked to ensure all units are included or the model runs will throw errors.



1.3)  Recursive Feature selection / Correlated variable reduction

To improve the interpretability of the models, we can firstly remove the correlated covariates. While there are several methods available to complete this task we chose a simple correlation matrix with a cutoff values of 0.9.  This is based on the entire raster surface (not just the points). The cuttoff parameters can be adjusted. 

```{r}
#| eval: false

mcols <- readRDS(fs::path(out_dir, "full_covariate_list.rds"))

reduced_vars <- reduce_features(mcols,
                                covar_dir = fs::path(PEMprepr::read_fid()$dir_1020_covariates$path_rel, "5m"),
                                covarkey = covarkey,
                                covtype = c("dem"),
                                cutoff = 0.90)

write.csv(reduced_vars, fs::path(out_dir, "reduced_covariate_list.csv"), row.names = FALSE)

```



## 1.4) prepare the training point models per BEC.

Once we have a reduced covariate list we prepare training points by splitting them into a list of points per bgc (or forest or non-forest) for the next steps in the process. This will also create a subfolder per BGC unit into which the model appropraite information will be contained. 

```{r}
#| eval: false

tpts <- read.csv( fs::path(out_dir, "training_pts.csv"))

model_bgc <- prep_model_tps(
  prepped_points = tpts,
  covars = reduced_vars,
  model_type = "f",
  outname = "model_input_pts.rds",
  out_dir = out_dir
)

```



# 1.5) Determine optimum parameters for the model

We use only the original data points (not the neighbours) and pure calls to tune the model hyperparameters. This includes estimating mtry and min_n to use for the models. Best accuracy is determined based on the roc_auc and accuracy metrics. We can also plot the each is exported to enable more assessment of best options. 


```{r}
#| eval: false
#| 
tune_bgc <- tune_model_params(
  prepped_points = model_bgc,
  covars = reduced_vars,
  min_no = 20,
  out_dir = out_dir,
  output_type = "best",
  accuracy_type = "roc_auc"
)


```



#1.6) Determine optimum Balance options for models

Datasets can vary widely in the proportion of classes and representation within the entire dataset. While this will likely reflect in part the distribution of class types on the ground, it can impact overall accuracy, with highly imbalances datasets likely to under represent uncommon data classes. The advantage of balancing datasets is to decrease the overprediction of the major classes and increase the rate of predicting the minority classes. This impacts the overall accuracy measure measures. More details and testing in regards to balanceing can be found in Appendix 3. 
We explored two method to assess the impact of balance on overall accuracy and map unit accuracy. This included:
1) synthetic minority oversampling technique (SMOTE) to create pseudo data to inform under sampled units and 
2) downsampling, a method to subsample the most common classes. 
To determine the impact of balancing on individual variants we tested a number of options combining smoting and downsampling using the themis R package. In this package we build a model recipe in which we define a number of steps to preprocess the data and apply the model to the data set. These methods are used to adjust the ratio by which minority and majority classes are represented. 


Balancing optimizing process

To determine optimum smoting/downsampling parameters we apply all possible combinations of smoting and downsampling to a given input dataset (ie. Stage 1 sampling of  a particular BGC unit). The range of parameters tested in this method include downsampling on a ratio of 1-100 at 10 unit increments (10, 20, 30, 40, 50, 60, 70, 80, 90). For example selecting a downsample ratio of 50 will result in the majority class to be downsampled so the minority class is half as many as the majority level.
Smoting parameters ranged from 0 – 1 with increments of 0.1 (i.e 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7,0.8,0.9). A value of 1 means all classes will be up sampled to equal number with the majority class, For example a value of 0.5 would mean that the minority levels will have (at most) (approximately) half as many rows than the majority level.
We can use the function run_base_model() and balance_optimisation_iteration() to run all options and out a summary figure to determine the best option. The following balancing options are tested using this script. 
run_base_model() : 
1. Raw (no balancing applied) 
balance_optimisation_iteration() 
1.	down sample (under ratio = 0 - 100) (15, 20, 30, 40, 50, 60, 70, 80, 90).
2.	smote (over ratio = 0 - 1), (i.e 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7,0.8,0.9).
3.	downsample and smote combination (combination of both under/over ratios) ie: ds_50_sm_0.3 (downsample to 50% and upsmote to 0.3)
For each of these 110 models we run the model using a leave one out approach to iterate over slices of data. This provided information about the range in confidence intervals for the entire data set. We also use this information to assess how over or under predicted each of the classes are for each model run. This will form the basis of selecting the optimum balancing parameters (see below for more details on assessment). 



Practical considerations: 
1. For data sets with less than 2 slices, we iterate by transect, rather than slice to provide uncertainty measures. 

2. For classes that have very few samples, smoting is not possible. While we remove classes that have less than 10 units in the entire dataset, it can occur that a given slice has very few of a particular class, but the class is well represented across all sites. When this occurs in a particular slice used for the test data set we skip this slice. The unit however will be retained when it occurs in the training data set. The slice will be skipped and the iteration continues. 

3. In some cases certain smoting or balancing options result in errors which are caused by too few points. In many of these cases we can remove the specific combination from the balancing optimization testing and continue with other options. This typically occurs for smote ratio = 0.1 – 0.3 or downsample at 10 and 15.
3. Optimum balancing parameters will vary depending on the imbalanced nature of the data sets and should be run for each data set individually. 
 
Selecting the optimum balance combination 

Once all the balance options have been run we can determine the option with the best accuracy (based on various metrics). This uses the functions combine_balance_outputs() to combine all metrics and then select_best_acc() function to estimate the best balance. We use the deviation from the raw outputs (ie no balance) as a measure of improvement and include a percent difference 
We generate these values for the following metrics for aspatial estimates: aspat_paf_theta.5, aspat_paf_theta0, aspat_paf_theta1, aspatial_sum and for spatial estimates : spat_paf_theta.5, spat_paf_theta0, spat_paf_theta1, spatial_sum. 

We also generate best overall value which is a balance of both aspatial and spatial, in which the difference from raw is the best model combined. 
This is output in as "best_balancing.csv" in the model inputs folder: 

This shows the best balance option for each metric type (maxmetric) including the accuracy value (max) as compared to the raw, and the percent improvement for each bgc. This allows users to select the best balance as per the desired metric choice given the application of the map. We use overall as the default value as it balances both aspatial and spatial metrics. 


Once the optimal balance metric is decided we can also generate the optimized theta for each of the Bec variants fo this specific balance level. To estimate theta values the model needs to be rerun with the full outputs. 
This is an optional step for more detailed outputs. 


```{r}
#| eval: false

out_dir = fs::path(PEMprepr::read_fid()$dir_3020_draft$path_rel, "20_f")

fuzz_matrix <- read.csv(fs::path(out_dir , "fuzzy_matrix.csv" )) |>
  dplyr::select(target, Pred, fVal)

covars = read.csv(fs::path(out_dir , "reduced_covariate_list.csv")) |> dplyr::pull()
# read in data
bgc_pts_subzone <- readRDS(fs::path(out_dir , "model_input_pts.rds"))

run_balance_optimisation(bgc_pts_subzone,
                         fuzz_matrix,
                         covars,
                         extra_pts = FALSE,
                         out_dir,
                         ds_iterations = c(10, 20,  30, 40, 50, 60, 70, 80, 90),
                         smote_iterations = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9),
                         use_neighbours = FALSE)


```







## 2) Run the forest model

The model framework is based on an iterative leave-one-out process in which the accuracy estimates are generate by holding out one part of the data and then building and predicting with the other portion. Accuracy results are generated for each slice and uncertainty is estimated for the entire model. 
Accuracy is based on iteration by slice, or by site, where slice numbers are low. 
The rational for this is to reduce the need for a separate QA, and to improve uncertainty estimates of predictions. Each slice represents similar hypercube “space” and contains approximately 5 sites. For example stage 1 SBSmc2 at Deception includes 5 slices each with 5 sites = 25 sites or 50 triangles in total. 

This provides; 
1) confidence intervals around accuracy measures (based on 5 slices), 
2) minimize “data leakage” between the test and training sets, 
3) enables sites to be “blocked” to training and testing sets to prevent the model from training and testing on data from the same site (ie pair of transects). Cross validation is stratified by mapunit and grouped by site id. Test results are reported below.
4) To ensure an accurate assessment we calculate the average weighted means and standard deviation based on the number of transects per slice. This accounts for sampling structure where there are uneven number of sites per slice. 

There are a number of additional parameters that can be used to fine tune the model. These include 

1) Use of neighbours. The neighbors designates whether neighboring cells should be included in the model build.

2) Extra pts. If additional points are to be added, those collected outside the standard framework, functions include a extra_pts = TRUE/FALSE parameter. The default is set to FALSE. If additional points are to be added these are designated as "incidental" in the data_type column. These can be further sorted and refined by the user if required. In any case where additional points are used, these points are only included in the training dataset and not the test dataset. 

3) Balancing options (downsample_ratio/ smote_ratio)

4) theta values 

5) Report 

6) detailed outputs. 


```{r run full model}
#| eval: false

out_dir = fs::path(PEMprepr::read_fid()$dir_3020_draft$path_rel, "20_f")

# read in data
bgc_pts_subzone <- readRDS(fs::path(out_dir, "model_input_pts.rds"))

# read in fuzzy matrix
fuzz_matrix <- read.csv(file.path(out_dir, "fuzzy_matrix.csv" )) |>
  dplyr::select(target, Pred, fVal)

# read covariate list
covars = read.csv(fs::path(out_dir, "reduced_covariate_list.csv")) |> dplyr::pull()

#read forest_nonforest binary template
nf_f_filter <- rast(fs::path(PEMprepr::read_fid()$dir_3010_inputs$path_abs, "forest_nonforest_final.tif"))



# for each bec zone this needs to be run independently to accommodate different model requirements. 

# example 1: ICHmc1


bec <- "ICHmc1" #"ESSFwv" "ICHmc2"
out_bgc_dir <- fs::path(out_dir, bec)

# read best tune
best_tune <- utils::read.csv(fs::path(out_bgc_dir, "best_tuning.csv"))
mtry <- best_tune$mtry
min_n <- best_tune$min_n

out <- run_full_model(
    model_name = "base_model",
    bgc_pts_subzone = bgc_pts_subzone,
    bec = bec,
    fuzz_matrix = fuzz_matrix,
    covars = covars,
    use_neighbours = FALSE,
    extra_pts = FALSE,
    mtry = mtry,
    min_n = min_n,
    ntrees = 151,
    downsample_ratio = FALSE,
    smote_ratio = FALSE,
    nf_f_filter = nf_f_filter,
    theta = c(0,1),
    report = FALSE,
    detailed_output = TRUE,
    out_dir = out_bgc_dir)


```




```{r run final model}
#| eval: false


######################
# 3) Run final model
######################

out_dir = fs::path(PEMprepr::read_fid()$dir_3020_draft$path_rel, "20_f")

# read in data
bgc_pts_subzone <- readRDS(fs::path(out_dir, "model_input_pts.rds"))

# read covariate list
covars = read.csv(fs::path(out_dir, "reduced_covariate_list.csv")) |> dplyr::pull()

bec <- "ICHmc1"
out_bgc_dir <- fs::path(out_dir, bec)

# read best tune
best_tune <- utils::read.csv(fs::path(out_bgc_dir, "best_tuning.csv"))
mtry <- best_tune$mtry
min_n <- best_tune$min_n
ntrees <- 151


final_mod <- run_final_model(model_name = "final",
                             bgc_pts_subzone = bgc_pts_subzone,
                             bec = bec,
                             covars = covars,
                             extra_pts = FALSE,
                             mtry = mtry,
                             min_n = min_n,
                             ntrees = ntrees,
                             report = TRUE,
                             downsample_ratio = FALSE,
                             smote_ratio = FALSE,
                             out_dir = out_bgc_dir)




```





```{r predict map}
#| eval: false


######################
# 4) Predict maps
######################

library(PEMmodelr)
bec = "ICHmc1"
model_dir = fs::path(PEMprepr::read_fid()$dir_3020_draft$path_rel, "20_f")
covars = read.csv(fs::path(model_dir, "reduced_covariate_list.csv")) |>  dplyr::pull()
cov_dir = fs::path(PEMprepr::read_fid()$dir_1020_covariates$path_rel, "5m")
tile_dir = fs::path(PEMprepr::read_fid()$dir_30_model$path_rel,"tiles")
bec_shp <- sf::st_read(fs::path(PEMprepr::read_fid()$dir_1010_vector$path_rel,"bec.gpkg"), quiet = TRUE)

model_name = "final_model_final.rds"
model = fs::path(model_dir, bec, model_name)
out_dir <- fs::path(model_dir, bec, "map")
map_label = "final_map.tif"


predict_map(
  bec = bec,
  bec_shp = bec_shp,
  model = model,
  covars = covars,
  cov_dir = cov_dir,
  tile_dir = tile_dir,
  out_dir = out_dir,
  map_label = map_label
)




























```{r}
#| eval: false

# designate the directory
out_dir = fs::path(PEMprepr::read_fid()$dir_3020_draft$path_rel, "20_f")

# read in data
bgc_pts_subzone <- readRDS(fs::path(out_dir, "model_input_pts.rds"))

# read in fuzzy matrix
fmat <- read.csv(file.path(out_dir, "fuzzy_matrix.csv" )) |>
  dplyr::select(target, Pred, fVal)

# read in reduced covariate list 
covars = read.csv(fs::path(out_dir, "reduced_covariate_list.csv")) |> dplyr::pull()

## Run base model
run_base_model(
  bgc_pts_subzone = bgc_pts_subzone,
  fuzz_matrix = fuzz_matrix,
  covars = covars,
  use_neighbours = FALSE,
  extra_pts = TRUE,
  report = FALSE,
  detailed_output = TRUE,
  out_dir = out_dir)


```



# 3) Run final model

If we are looking for a simple unbalanced and base output we can use this model to generate a final fit. Note random forest are highly susceptible to imbalance in training points and these features will be discussed below. 

The final fit uses all the data and does not use Leave-one-out process. 
This can be run with the raw data (unbalanced) or with the balanced outputs. 

```{r}
#| eval: false

out_dir = fs::path(PEMprepr::read_fid()$dir_3020_draft$path_rel, "20_f")
train_data <- readRDS(fs::path(out_dir, "model_input_pts.rds"))
covars <- read.csv(fs::path(out_dir, "reduced_covariate_list.csv")) |> dplyr::pull()

final_mod <- run_final_model(train_data,
                             covars,
                             model_bal = "base",
                             report = FALSE,
                             extra_pts = TRUE,
                             out_dir = out_dir)

```


# 4) Predict maps

We can use the final model fit to predict a forest map per BGC. This function applies to all model types (forest/nonforest, forest and non-forest) as controlled by model type. Model type "f" denotes that the map will be built from individual BGC models and stitched together. Models are predicted onto tiles with a default of 500m size. 

A tile directory will be built and tiles generated on the first time the model is run. These tiles are used for each submodel. 

In this example we use the reduced covariate list however the full covariate list can also be used. 


```{r}
#| eval: false

model_dir = fs::path(PEMprepr::read_fid()$dir_3020_draft$path_rel, "20_f")
covars = read.csv(fs::path(model_dir, "reduced_covariate_list.csv")) |>  dplyr::pull()
cov_dir = fs::path(PEMprepr::read_fid()$dir_1020_covariates$path_rel, "5m")
tile_dir = fs::path(PEMprepr::read_fid()$dir_30_model$path_rel,"tiles")
bec_shp <- sf::st_read(fs::path(PEMprepr::read_fid()$dir_1010_vector$path_rel,"bec.gpkg"), quiet = TRUE)

run_predict_map(
  model_type = "f",
  model_dir = model_dir,
  model_name = "final_model_base.rds",
  covars = covars,
  cov_dir = cov_dir,
  tile_dir = tile_dir,
  bec_shp = bec_shp
)

```




# 5) Advanced modelling options (OPTIONAL)

While the above workflow provides a basic model fit, we can also use more advanced modelling options to improve the accuracy of the model. This includes balancing the training points and determining the optimum theta value for the model.


# 5.1)  Determine optimum Theta value for the metric of choice

While we generate values for theta at 0, 1, and 0.5, we can calculate the optimal theta value, that is then 75% of the values are about the threshold of 0.65 accuracy. 

This relies on the output of the detailed output from the base model to regenerated. If this was set to FALSE, it might need to be regenerate. 

The function below uses the detailed outputs to generate the values for each theta value (0.1 – 0.9) and then determine at which theta value is 75% of results are above 0.65 accuracy level. 

The output of the function is a csv "compiled_theta_results.csv" which contains all accuracy metrics along with a summarized output csv ("theta_thresholds.csv") which specifies all theta values tested, the mean, 25 and 75 quartiles and which were above the threshold (TRUE/FALSE). These results are generated for each type (p - primary, pa - primary secondary, paf - primary, secondary, and fuzzy). 

```{r}
#| eval: false

out_dir = fs::path(PEMprepr::read_fid()$dir_3020_draft$path_rel, "20_f")

# read in data
bgc_pts_subzone <- readRDS(fs::path(out_dir, "model_input_pts.rds"))

# read in fuzzy matrix
fuzz_matrix <- read.csv(file.path(out_dir, "fuzzy_matrix.csv" )) |>
  dplyr::select(target, Pred, fVal)

run_theta_metrics(bgc_pts_subzone, out_dir, fuzz_matrix, overwrite = TRUE)

```



















# 5.3) Run the final model with the optimal balance

Once we have gone though these steps and assessed the optimum balancing and theta for the desires accuracy measure we can can run the final model with the balance option. 

The options available include: c( "aspat_paf_theta.5" ,"aspat_paf_theta0" ,
"aspat_paf_theta1" , "aspatial_sum", "spat_paf_theta.5" , "spat_paf_theta0", "spat_paf_theta1",
 "spatial_sum", "overall")


```{r}
#| eval: false

out_dir = fs::path(PEMprepr::read_fid()$dir_3020_draft$path_rel, "20_f")

fuzz_matrix <- read.csv(fs::path(out_dir , "fuzzy_matrix.csv" )) |>
  dplyr::select(target, Pred, fVal)

covars = read.csv(fs::path(out_dir , "reduced_covariate_list.csv")) |> dplyr::pull()

bgc_pts_subzone <- readRDS(fs::path(out_dir , "model_input_pts.rds"))

model_bal = "aspat_paf_theta0"

# "aspat_paf_theta.5" ,"aspat_paf_theta0" ,
# "aspat_paf_theta1" , "aspatial_sum", "spat_paf_theta.5" , "spat_paf_theta0", "spat_paf_theta1",
#  "spatial_sum", "overall"

run_final_model(
  train_data = bgc_pts_subzone,
  covars = covars,
  model_bal = model_bal,
  report = FALSE,
  out_dir = out_dir,
  extra_pts = FALSE,
  ds_ratio = NA,
  sm_ratio = NA
)

```


# 5.4) Predict maps -  balanced model

```{r}
#| eval: false

model_dir = fs::path(PEMprepr::read_fid()$dir_3020_draft$path_rel, "20_f")
covars = read.csv(fs::path(model_dir, "reduced_covariate_list.csv")) |>  dplyr::pull()
cov_dir = fs::path(PEMprepr::read_fid()$dir_1020_covariates$path_rel, "5m")
tile_dir = fs::path(PEMprepr::read_fid()$dir_30_model$path_rel,"tiles")
bec_shp = sf::st_read(fs::path(PEMprepr::read_fid()$dir_1010_vector$path_rel,"bec.gpkg"), quiet = TRUE)
model_name = "final_model_aspat_paf_theta0.rds"

run_predict_map(
  model_type = "f",
  model_dir = model_dir,
  covars = covars,
  cov_dir = cov_dir,
  tile_dir = tile_dir,
  bec_shp = bec_shp
)


```

