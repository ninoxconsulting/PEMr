---
title: "Post_data_collection_04"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Post_data_collection_04}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(PEMr)
```


# Post Fieldwork data processing 

```{r}
#| eval: false
# read in the raw field data and prepare it for PEM analysis
library(PEMsamplr)

#remotes::install_github("ninoxconsulting/PEMmodelr", ref = "prep_training_data")
library(PEMmodelr)

```

Firstly we will generate a transect layout with all transects using the function generate_transectlayout()

```{r, eval = FALSE}
#| eval: false
# set up folder paths

# location of final s1_sample plan / gpkg + where transect_layout will reside
#input_file <- fs::path(PEMprepr::read_fid()$dir_20104020_transect$path_abs, "s1_sampling.gpkg")
input_path <- PEMprepr::read_fid()$dir_20104020_transect$path_rel

# location where the final simplified transect layer will be stored
out_dir = PEMprepr::read_fid()$dir_201040_plan_final$path_rel

# generate simple transect plan layer
transect_layout <- simplify_transectlayout(input_path, 
                                           out_dir, 
                                           write_output = FALSE, 
                                           overwrite = FALSE)

```


For this packages we have created a demo dataset which can be used to test the functions. 

```{r}
#| eval: false
# for test aoi - prepared field data
# read in the prepped transect layout and buffer
transect_layout <- sf::st_read(fs::path(out_dir, "transect_layout_date_creek_demo.gpkg"))

```



Format field data: 

Once all the field data is collected it will be saved in a single folder. The coding allows for files to be saved within subfolders. 


The format_fielddata() function is used to standardize and consolidate field data. This runs a number of checks including: 
-	mandatory fields are present
-	Format date/times
-	Format Transect names by intersection with transects layer above
-	Fill missing observers 
-	Check all mandatory data is included
-	Assign data type (s1 – standard sample 1, and incidentals) 

The script will provide messages where data fails to meet requirements or needs more edits before the data can be consolidated. 
This should be an iterative process in which the user runs the function, checks for errors , corrects and re-runs until it can be consolidated.


Additional/ incidental data points. 

In many cases, additional data points may be collected outside the standard transect layout. This is particularly the case for uncommon site series of mapping units. In these cases additional data can be collected and incorporated into the models. This is incorporated into the workflow with the designation of extra_pts is TRUE or FALSE in many following function. 

If additional data is collected outside the standard methodology, the name of file should be specified in the format_fielddata() function, as it will not be put through the entire list of checks that is relevant to transect data. 

In the example below the additional points dataset is called "additional_points.gpkg" and is stored in the same folder as the raw field data.


```{r}
#| eval: false
# location of the raw field data
rawdat <- PEMprepr::read_fid()$dir_20105010_raw_field_data$path_rel

#location where cleaned data will be stored
cleandat <- PEMprepr::read_fid()$dir_20105020_clean_field_data$path_rel

# import and clean field data
points <- format_fielddata(rawdat,
  transect_layout,
  buffer = 10,
  write_output = TRUE,
  extra_points = "additional_points.gpkg",
  out_dir = fs::path(PEMprepr::read_fid()$dir_20105020_clean_field_data$path_rel),
  out_name = "s1_points_raw.gpkg"
)

```


Format tracklog  

In addition to training point, we consolidate all track logs which are used for QA reference using the function: format_tracklog() . this will compile all tracklogs to together into a single geopackage that can be used for 


```{r}
#| eval: false
# format tracklog (optional)
tracks <- format_tracklog(rawdat,
  transect_layout,
  buffer = 10,
  write_output = TRUE,
  out_dir = fs::path(PEMprepr::read_fid()$dir_20105020_clean_field_data$path_rel),
  out_name = "s1_track_raw.gpkg"
)

```


# Generate mapkey

```{r}
#| eval: false
# check and clean up field data names
key <- generate_mapkey(
  data_pts  = fs::path(PEMprepr::read_fid()$dir_20105020_clean_field_data$path_rel, "s1_points_raw.gpkg"),
  write_output = TRUE,
  out_dir = fs::path(PEMprepr::read_fid()$dir_30_model$path_rel),
  out_name = "mapunitkey.csv"
)

```



# Manually review the generated basemap key file (mapunit.key) and add missing
# basemapunit calls if needed.


Before we begin processing the standard transect data, we can split out any additional data points that have been collected. This can be done by filtering the data_type column in the points data. These will be added back following the processing of the standard transect. 


```{r}
#| eval: false
extra_pts <- points |>
  dplyr::filter(data_type == "incidental")

sf::st_geometry(extra_pts) <- "geometry"

```


Once the point data has been reviewed we use the make_lines() to attribute the lines between each of the points. This is based on the order attribute and can also be used to check that the points are in logical order. 

```{r}
#| eval: false
# convert the points data to cleaned points to line segments
processed_transects <- make_lines(
  points = points,
  transect_layout = transect_layout,
  method = "pts2lines",
  buffer = 20,
  write_output = TRUE,
  out_dir = fs::path(PEMprepr::read_fid()$dir_20105020_clean_field_data$path_rel),
  out_name = "proc_s1_transects5.gpkg"
)

```

5.2.2. Convert line segments to points 

The first step in the process is to convert the line segments to points in the matching raster which we are using. We use the convert_lines_pts() function to create a point file that contains all the values of lines within the template of the raster. 
Note this will result in some points being attributed outside the space of the lines and will be addressed with the spatial misregistration and neighbourhood calculation accuracy metrics. 

By default we now add two rings of neighboutind cells around each individual point. These are denoted in the column position in which the original cell is labelled “Orig” and “Adj” cells are the surrounding cells. Adj1-9 represent the first ring around the original cell, and 10 - 17 is the second ring around the original cells. Each pixal is attributed by an ID column to enable for inclusion or exclusion of neighbours in future calculations. 


```{r}
#| eval: false
# convert pt to lines

processed_pts <- convert_lines_pts(
  processed_lines = processed_transects,
  buffer = 2.5,
  trast = fs::path(PEMprepr::read_fid()$dir_1020_covariates$path_rel, "5m", "template.tif"),
  write_output = TRUE,
  out_dir = PEMprepr::read_fid()$dir_20105020_clean_field_data$path_rel,
  out_name = "allpoints.gpkg"
)

```


If we had additional points we can now add these to the processed standard points. 


```{r}
#| eval: false
# add the extra points + the processed line points and attribute all data

processed_pts <- dplyr::bind_rows(processed_pts, extra_pts)

```



5.2.4. Attribute all points 

Once we have all the training point data prepped, we can attribute with all the rasters within the given resolution. Ie: 5m as default.
We use the attribute_points() function which will intersect each point with a terra stack. This function points to filepath, so ensure that all rasters within the stack are aligned and also required for the analysis. 


```{r}
#| eval: false
att_pts <- attribute_points(
  data_pts = processed_pts,
  cov_dir = fs::path(PEMprepr::read_fid()$dir_1020_covariates$path_rel, "5m"),
  write_output = FALSE,
  out_dir = fs::path(PEMprepr::read_fid()$dir_20105030_attributed_field_data$path_rel),
  out_name = "allpoints_att.gpkg")
```


## generate a covariate key file


# manually check the key and assign the correct covariate type to each column


```{r}
#| eval: false
generate_covar_key(att_pts, overwrite = TRUE)

```

## Congratulations you are now ready to start modelling


